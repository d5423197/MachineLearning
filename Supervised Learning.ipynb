{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning \n",
    " - are trained using labeled examples\n",
    "\n",
    "\n",
    "## 1. Example: <br>\n",
    "Spam vs Legitimate <br>\n",
    "Positive vs Negative reviews\n",
    "\n",
    "\n",
    "## 2. Machine learing process<br>\n",
    "collect data -> data cleaning -> split data into train/test/validation data -> train model -> test model(use validation data) -> adjust model based on testing result -> get the performance(using test data)-> model deployment\n",
    "\n",
    "---\n",
    "Trianing data\n",
    "- used to train model parameters<br>\n",
    "\n",
    "Validation data\n",
    "- used to adjust hyperparameters<br>\n",
    "\n",
    "Test data\n",
    "- used to get some final performance\n",
    "\n",
    "\n",
    "## 3. Model evaluation <br>\n",
    "### 3.1 Classification evaluation <br>\n",
    "- Accuracy $$\\frac{total\\;correct\\;Predictions}{total\\;Predictions}$$<br>\n",
    "When unbalanced classes occur, accuracy is not a good method to evaluate model\n",
    "\n",
    "- Recall $$\\frac{true\\;positives}{true\\;positives + false\\;negatives}$$\n",
    "\n",
    "- Precision $$\\frac{true\\;positives}{true\\;positives + false\\;positives}$$\n",
    "Recall expresses the ability to find all relevant instances in a dataset, precision expresses the proportion of the data points our model says was relevant actually were relevant <br>\n",
    "\n",
    "- F1-Score $$F1 = 2*\\frac{precision * recall}{precision + recall}$$\n",
    "\n",
    "---\n",
    "Confusion matrix\n",
    "\n",
    "| total population | predicted positive | prediction negative |\n",
    "| --- | --- | --- |\n",
    "| condition positive | True Positive(TP) | False Negative(FN) <br> (Type 2 error) |\n",
    "| condition negative | False Positive(FP) <br> (Type 1 error) | True Negative(TN) |\n",
    "\n",
    "### 3.2 Regression evaluation\n",
    "\n",
    "- Mean Absolute Error (MAE) <br>\n",
    "MAE won't punish large errors\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y_i}|$$\n",
    "\n",
    "- Mean Squared Error (MSQ) <br>\n",
    "If we take squre of the error, large errors would be noticed\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "- Root Mean Square Error (RMSE) <br>\n",
    "Sometimes the unit is difficult to understand when using MSQ <br>\n",
    "This is the most popular one because it punishes the large errors and has the same units as y\n",
    "$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://scikit-learn.org/stable/_static/ml_map.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
